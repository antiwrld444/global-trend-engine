# Отчет по модулю дедупликации (Deduplication)

## Что реализовано:
1.  **Семантический анализ в `NLPProcessor`**:
    *   Интегрирована модель `sentence-transformers/all-MiniLM-L6-v2` для получения эмбеддингов текстов.
    *   Добавлены методы `get_embedding` и `calculate_similarity` для вычисления косинусного сходства между заголовками трендов.
2.  **Логика дедупликации в `DBManager`**:
    *   При вызове `save_trend` теперь происходит поиск среди последних 100 записей в базе данных.
    *   Если найден тренд с коэффициентом сходства > 0.85, новая запись не создается.
    *   Вместо этого у существующего тренда увеличивается `mentions_count` и обновляется `timestamp`.
    *   Обновляется история (score) для существующего тренда на основе нового упоминания.
3.  **Тестирование**:
    *   Создан тест `tests/test_deduplication.py`, подтверждающий корректность объединения семантически близких заголовков (Similarity ~0.97).

## Преимущества:
*   **Чистота данных**: Избегаем дублирования одной и той же новости из разных источников.
*   **Качество скоринга**: Вес тренда теперь честно суммируется при упоминании в разных СМИ, даже если заголовки сформулированы иначе.
*   **Актуальность**: Обновляемый `timestamp` позволяет видеть, какие темы активны прямо сейчас.

## Технические детали:
*   Модель: `all-MiniLM-L6-v2` (легкая и быстрая).
*   Порог сходства: 0.85 (выбран для баланса между точностью и агрессивностью группировки).
